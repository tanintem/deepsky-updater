{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys, requests, shutil, os\n",
    "from urllib import request, error\n",
    "from datetime import date, timedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    def __init__(self, region, root_region_url, base_url, verbose=False):\n",
    "        self.damaged_file = []\n",
    "        self.undownload_file = []\n",
    "        self.verbose = verbose\n",
    "        self.region = region\n",
    "        self.root_region_url = root_region_url\n",
    "        self.base_url = base_url\n",
    "        self.root_dir = str(\"./input/\")\n",
    "        #Creating folder and subfolder given the format /input/[Region-zone]/[timestamp as date]/[IMG]\n",
    "        self.utc_date_now = datetime.datetime.utcnow().date()\n",
    "        dirs = [\"./input\"]\n",
    "        for d in dirs:\n",
    "            if not os.path.exists(d):\n",
    "                os.makedirs(d)\n",
    "    \n",
    "    def get_file_path(self, img_name):#For assigning timestamp dir to Img\n",
    "        utc_time = datetime.datetime.utcnow() #utc time right now\n",
    "        #extract timestamp of file name\n",
    "        img_hour = img_name.split(\"_\")[-1].split(\".\")[0][:2]\n",
    "        img_min = img_name.split(\"_\")[-1].split(\".\")[0][2:]\n",
    "        img_time = datetime.datetime.utcnow()\n",
    "        img_time = img_time.replace(hour=int(img_hour), minute=int(img_min), second=0, microsecond=0)\n",
    "        \n",
    "        if self.verbose: #for debugging\n",
    "            print(\"UTC time right now:\"+str(utc_time)+\", Img timestamp:\"+str(img_time))\n",
    "        file_path = str(self.root_dir)\n",
    "        \n",
    "        return file_path\n",
    "    \n",
    "    def fetch_img(self, path, file_path):\n",
    "        url=path\n",
    "        try:\n",
    "            response=requests.get(url, stream=True)\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            if self.verbose:\n",
    "                print(\"Connection Abort\") #INCASE OF FAILED LINK, SKIP IT! DOWNLOAD LATER\n",
    "            return False\n",
    "        if str(response.status_code) == \"404\":\n",
    "            if self.verbose:\n",
    "                print(\"404 error\")\n",
    "            return False\n",
    "        with open(file_path+\"/image.jpg\", 'wb') as out_file: #download IMG as image.jpg, will change name later\n",
    "            shutil.copyfileobj(response.raw, out_file)\n",
    "        del response    \n",
    "        return True\n",
    "        \n",
    "    def scraping(self):\n",
    "        current = datetime.datetime.utcnow()- timedelta( minutes=20)#ต้องดึงของ10 นาทีก่อน\n",
    "        current=current.strftime(\"%H%M\") \n",
    "        time=int(current)-int(current)%10\n",
    "        time=('0000'+str(time))[4:]\n",
    "\n",
    "        band = \"se1_b08\"\n",
    "\n",
    "        links = []\n",
    "        req = request.Request(self.root_region_url)\n",
    "        with request.urlopen(req) as response:\n",
    "            html = response.read().decode(\"utf-8\")#extract all imgs link from html\n",
    "            for un_slice_url in html.split(\"<a href=\")[1:]:\n",
    "                if band in un_slice_url and str(time) in un_slice_url:\n",
    "                    links.append(self.base_url + un_slice_url.split(\">\")[0])#fill extrated links into an array\n",
    "\n",
    "\n",
    "        \n",
    "        #for every picture links\n",
    "        for link in links:\n",
    "            #extract image name from url\n",
    "            #Example: http://www.data.jma.go.jp/mscweb/data/himawari/img/se1/se1_b13_0000.jpg\n",
    "            #will extract se1_b13_000.jpg from url above\n",
    "            img_name = link.split(\"/\")[-1]\n",
    "            file_path = self.get_file_path(img_name)#to verify timestamp directory of this picture\n",
    "            if not file_path:\n",
    "                if self.verbose:\n",
    "                    print(\"utc_time == img_time, Skip\")\n",
    "                self.undownload_file.append(link)\n",
    "                continue\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(\"File path:\"+file_path+\"/\"+img_name)\n",
    "                \n",
    "            if os.path.exists(file_path+'/'+img_name):#incase of download existing file\n",
    "                if self.verbose:\n",
    "                    print(\"File Exists\")\n",
    "                continue\n",
    "            if self.fetch_img(link, file_path): #if Connection is success\n",
    "                if self.verbose:\n",
    "                    print(\"Connection success!\")\n",
    "                os.rename(file_path+'/image.jpg', file_path+'/'+ img_name) \n",
    "            else:\n",
    "                self.damaged_file.append(link)\n",
    "                \n",
    "                return None\n",
    "                #rename image.jpg into image format name\n",
    "                #Example:se1_b13_0000.jpg\n",
    "                #This format is AREA:BAND_TYPE:TIMESTAMP.jpg\n",
    "        #write Damaged file and undownload file to log\n",
    "        print(self.region+\" Damaged file\")\n",
    "        for i in self.damaged_file:\n",
    "            print(i)\n",
    "        print(\"\\n\"+self.region+\" Undownload file\")\n",
    "        for i in self.undownload_file:\n",
    "            print(i)\n",
    "        return img_name\n",
    "    \n",
    "#write log file if program terminated\n",
    "def exit_handler(*args):\n",
    "    for key in args:\n",
    "        if len(key.damaged_file)>0:\n",
    "            print(key.region+\" Damaged file\")\n",
    "            for i in key.damaged_file:\n",
    "                print(i)\n",
    "        if len(key.undownload_file)>0:\n",
    "            print(\"\\n\"+key.region+\" Undownload file\")\n",
    "            for i in key.undownload_file:\n",
    "                print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from line_killer import Img_preprocess\n",
    "from shutil import copyfile\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as f\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from CovLstm_cell_simply import ConvLSTMCell as Covlstm_cell\n",
    "import scipy.misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Covlstm_cell(1,1)\n",
    "        self.decoder = Covlstm_cell(1,1)\n",
    "        #self.hidden_size = hidden_size\n",
    "        #self.Convlstm_cell = Covlstm_cell(num_cell,hidden_size)\n",
    "        #self.relu = nn.ReLU()\n",
    "    def forward(self,data,epoch,T_en,T_de): #T_en = input sequence, T_de = output sequence\n",
    "        encoder_state = None\n",
    "        decoder_state = None\n",
    "        for t in range(epoch, T_en):\n",
    "              encoder_state = self.encoder.forward(data[t],encoder_state)\n",
    "        decoder_input = encoder_state[0][0]\n",
    "        decoder_input = decoder_input[:,None,:,:] \n",
    "        for t in range(0,T_de) :\n",
    "            decoder_state = self.decoder.forward(decoder_input,decoder_state)\n",
    "        y_pre = decoder_state[0][0][0]\n",
    "        # Dont care about hidden states\n",
    "        return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiate model\n",
      "model(\n",
      "  (encoder): ConvLSTMCell(\n",
      "    (Gates): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): ConvLSTMCell(\n",
      "    (Gates): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Create a MSE criterion\n",
      "MSELoss()\n",
      "optimizer Adam\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\CovLstm_cell_simply.py:14: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  torch.nn.init.xavier_normal(self.Gates.weight)\n",
      "C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\CovLstm_cell_simply.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  torch.nn.init.constant(self.Gates.bias, 0)\n"
     ]
    }
   ],
   "source": [
    "T_de = 20\n",
    "lr = 0.001\n",
    "print('Instantiate model')\n",
    "m = model().cuda()\n",
    "print(repr(m))\n",
    "\n",
    "lendata = 100\n",
    "seq = 20\n",
    "lenpredict = 6\n",
    "\n",
    "print('Create a MSE criterion')\n",
    "loss_fn = nn.MSELoss().cuda()\n",
    "print(loss_fn)\n",
    "\n",
    "params = list(m.parameters()) \n",
    "print('optimizer Adam')\n",
    "optimizer = optim.Adam(params, lr=lr)\n",
    "print(optimizer)\n",
    "index = 0\n",
    "index_last_x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "m.load_state_dict(torch.load('model\\\\model1.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn1_1 = Covlstm_cell(1,1)\n",
    "        self.rnn1_2 = Covlstm_cell(1,1)\n",
    "        self.rnn1_3 = Covlstm_cell(1,1)\n",
    "        self.rnn2_1 = Covlstm_cell(1,1)       \n",
    "    def init_hiden(self):\n",
    "        hidden = []\n",
    "        hidden1_1 = None\n",
    "        hidden1_2 = None\n",
    "        hidden1_3 = None        \n",
    "        hidden2_1 = None\n",
    "        hidden.append(hidden1_1)\n",
    "        hidden.append(hidden1_2)\n",
    "        hidden.append(hidden1_3)\n",
    "        hidden.append(hidden2_1)\n",
    "        return hidden       \n",
    "    def forward(self,data,hidden):\n",
    "        hidden1_1 = hidden[0]\n",
    "        hidden1_2 = hidden[1]\n",
    "        hidden1_3 = hidden[2]        \n",
    "        hidden2_1 = hidden[3] \n",
    "        hidden1_1 = self.rnn1_1.forward(data ,hidden1_1)               \n",
    "        hidden1_2_input = hidden1_1[0][0]\n",
    "        hidden1_2_input = hidden1_2_input[:,None,:,:] \n",
    "        hidden1_2 = self.rnn1_2.forward(hidden1_2_input,hidden1_2)       \n",
    "        hidden1_3_input = hidden1_2[0][0]\n",
    "        hidden1_3_input = hidden1_3_input[:,None,:,:] \n",
    "        hidden1_3 = self.rnn1_3.forward(hidden1_3_input,hidden1_3)      \n",
    "        hidden2_1_input = hidden1_3[0][0]\n",
    "        hidden2_1_input = hidden2_1_input[:,None,:,:] \n",
    "        hidden2_1 = self.rnn2_1.forward(hidden2_1_input ,hidden2_1)\n",
    "        encoder_out = hidden2_1[0]\n",
    "        hidden = []\n",
    "        hidden.append(hidden1_1)\n",
    "        hidden.append(hidden1_2)\n",
    "        hidden.append(hidden1_3)\n",
    "        hidden.append(hidden2_1)\n",
    "        return encoder_out,hidden\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        num_c = [1, 1, 1]\n",
    "        h = [1,1,1]\n",
    "        self.rnn1_1 = Covlstm_cell(1,1)\n",
    "        self.rnn1_2 = Covlstm_cell(1,1)\n",
    "        self.rnn1_3 = Covlstm_cell(1,1)\n",
    "        self.rnn2_1 = Covlstm_cell(1,1)\n",
    "        \n",
    "    def forward(self,data,hidden_en):\n",
    "        hidden1_1 = hidden_en[3]\n",
    "        hidden1_2 = hidden_en[2]\n",
    "        hidden1_3 = hidden_en[1]     \n",
    "        hidden2_1 = hidden_en[0]     \n",
    "        hidden1_1 = self.rnn1_1.forward(data,hidden1_1)                \n",
    "        hidden1_2_input = hidden1_1[0][0]\n",
    "        hidden1_2_input = hidden1_2_input[:,None,:,:] \n",
    "        hidden1_2 = self.rnn1_2.forward(hidden1_2_input,hidden1_2)        \n",
    "        hidden1_3_input = hidden1_2[0][0]\n",
    "        hidden1_3_input = hidden1_3_input[:,None,:,:] \n",
    "        hidden1_3 = self.rnn1_3.forward(hidden1_3_input,hidden1_3)\n",
    "        hidden2_1_input = hidden1_3[0][0]\n",
    "        hidden2_1_input = hidden2_1_input[:,None,:,:] \n",
    "        hidden2_1 = self.rnn2_1.forward(hidden2_1_input ,hidden2_1)\n",
    "        out = hidden2_1[0]\n",
    "        hidden = []\n",
    "        hidden.append(hidden1_1)\n",
    "        hidden.append(hidden1_2)\n",
    "        hidden.append(hidden1_3)\n",
    "        hidden.append(hidden2_1)\n",
    "        return out,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #input_size_c = 1 hidden_size = h\n",
    "        self.enc  = Encoder()\n",
    "        self.dec  = Decoder()\n",
    "        \n",
    "    def forward(self,data,epoch):\n",
    "        hidden_en = self.enc.init_hiden()\n",
    "        T_en = 9 # same seq\n",
    "        T_en = T_en+epoch\n",
    "        for t in range(epoch, T_en):\n",
    "            enc_output,hidden_en = self.enc(data[t],hidden_en)\n",
    "        #self.dec.init_h0(hidden_en)\n",
    "        dec_output = enc_output\n",
    "\n",
    "        for t in range(epoch, T_en):\n",
    "            dec_output,hidden_en= self.dec(dec_output,hidden_en)\n",
    "        dec_output = dec_output[0][0]\n",
    "        return dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\CovLstm_cell_simply.py:14: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  torch.nn.init.xavier_normal(self.Gates.weight)\n",
      "C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\CovLstm_cell_simply.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  torch.nn.init.constant(self.Gates.bias, 0)\n"
     ]
    }
   ],
   "source": [
    "model_3hr = TraModel()\n",
    "dic_param = torch.load('model/model8_10seq_10000dataset.pt')\n",
    "model_3hr.load_state_dict(dic_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# load data ################\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import color\n",
    "from scipy import ndimage, misc\n",
    "import cloudy\n",
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [color.rgb2gray(imread(path)) for path in image_paths]\n",
    "    \n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray((images), dtype=np.float32)\n",
    "current = cloudy.get_data_dir('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "now=datetime.datetime.utcnow()\n",
    "start = now-timedelta(minutes=200)\n",
    "target=now.strftime('%H%M')[:3]\n",
    "for i in range(len(current)):\n",
    "    name= current[i][-8:-5]\n",
    "    if target == name:\n",
    "        break\n",
    "temp=current[:i+1]\n",
    "current=current[-20+len(temp):]\n",
    "current=current+temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(train_dir):\n",
    "    train_data = load_images(train_dir)\n",
    "    Nx_input = torch.from_numpy(train_data).cuda()\n",
    "    torch.manual_seed(0)\n",
    "    x_input = Nx_input[:]/255\n",
    "    x_input = x_input[:,None,None,:,:]\n",
    "    x_input = Variable(x_input).cuda()\n",
    "\n",
    "    epoch=0\n",
    "    T_en = 20\n",
    "    T_en = T_en+epoch\n",
    "    output = m(x_input,epoch,T_en,T_de)\n",
    "    img = output.cpu()\n",
    "    img = img.data.numpy()\n",
    "    #img.shape\n",
    "    img = img*255\n",
    "    image_name = \"prediction\\\\\"+train_dir[-1][-16:]\n",
    "    print(image_name)\n",
    "    scipy.misc.imsave(image_name, img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save_3hr(train_dir):\n",
    "    seq = 9\n",
    "    train_data = load_images(train_dir)\n",
    "    Nx_input = torch.from_numpy(train_data)\n",
    "    torch.manual_seed(0)\n",
    "    x_input = Nx_input[:]/255\n",
    "    x_input = x_input[:,None,None,:,:]\n",
    "    x_input = Variable(x_input)\n",
    "    epoch=0\n",
    "    T_en = 9\n",
    "    #T_en = T_en+epoch\n",
    "    output = model_3hr(x_input,epoch)\n",
    "    img = output.cpu() \n",
    "    img = img.data.numpy()\n",
    "    #img.shape\n",
    "    img = img*255\n",
    "    image_name = \"prediction_3hr\\\\\"+train_dir[-1][-16:]\n",
    "    print(image_name)\n",
    "    scipy.misc.imsave(image_name, img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current=current[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected a Tensor of type torch.FloatTensor but found a type torch.cuda.FloatTensor for sequence element 1 in sequence argument at position #1 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-265c617b75fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_and_save_3hr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-14e57dd40283>\u001b[0m in \u001b[0;36mpredict_and_save_3hr\u001b[1;34m(train_dir)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mT_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#T_en = T_en+epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_3hr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-b9456db0dc0e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data, epoch)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mT_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT_en\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT_en\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_en\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;31m#self.dec.init_h0(hidden_en)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mdec_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9034e3a348f9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data, hidden)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mhidden1_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mhidden2_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mhidden1_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn1_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mhidden1_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mhidden1_2_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden1_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mhidden1_2_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden1_2_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\deepsky real time updater\\CovLstm_cell_simply.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_, prev_state)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m#print(input_.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprev_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mstacked_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m        \u001b[1;31m# print('--prev_hidden size--')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m#print(prev_hidden.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected a Tensor of type torch.FloatTensor but found a type torch.cuda.FloatTensor for sequence element 1 in sequence argument at position #1 'tensors'"
     ]
    }
   ],
   "source": [
    "img = predict_and_save_3hr(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "\n",
    "def placeFile(ftp,filename,filedir):\n",
    "    try:\n",
    "        ftp.delete(filename)\n",
    "    except Exception as e:\n",
    "        print(e.message)\n",
    "    status = ftp.storbinary('STOR '+ filename, open(filedir,'rb')) #rb\n",
    "    print(\"upload file\",filename)\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'250 CWD command successful.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp = FTP('waws-prod-dm1-119.ftp.azurewebsites.windows.net')\n",
    "ftp.login(user='deepsky\\$deepsky',\n",
    "      passwd='khqWN6sZlqler3u4CGxoHX4wWF1jeqCC2YfpCiEjiLPTvhrbc4ffuvn0gq1s')\n",
    "ftp.cwd('site/public/storage/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload file se1_b08_0320.jpg\n",
      "226 Transfer complete.\n"
     ]
    }
   ],
   "source": [
    "img_name='se1_b08_0320.jpg'\n",
    "placeFile(ftp,filename=img_name,filedir='input1\\\\'+img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# schedule for every 10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sched, time\n",
    "s = sched.scheduler(time.time, time.sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try scraping\n",
      "UTC time right now:2019-01-10 14:08:36.233162, Img timestamp:2019-01-10 13:40:00\n",
      "File path:./input//se1_b08_1340.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1340.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1340.jpg\n",
      "predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "c:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "c:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\\se1_b08_1340.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1340.jpg\n",
      "226 Transfer complete.\n"
     ]
    }
   ],
   "source": [
    "#def real_time_update(sc):\n",
    "##scrap part\n",
    "try:\n",
    "    print(\"try scraping\")\n",
    "    SE1 = Scraper(region = \"se1\",\n",
    "                 root_region_url = \"http://www.data.jma.go.jp/mscweb/data/himawari/list_se1.html\",\n",
    "                 base_url = \"http://www.data.jma.go.jp/mscweb/data/himawari/\",\n",
    "                 verbose = True)\n",
    "\n",
    "    try:\n",
    "        img_name=SE1.scraping()\n",
    "    except KeyboardInterrupt:\n",
    "        #rint(\"fail scraping\")\n",
    "        exit_handler(SE1)\n",
    "    #    \n",
    "    if img_name is not None:\n",
    "        path = os.path.abspath('input\\\\'+img_name)\n",
    "        print(\"store image\")\n",
    "        #store original image\n",
    "        ftp = FTP('waws-prod-dm1-119.ftp.azurewebsites.windows.net')\n",
    "        ftp.login(user='deepsky\\$deepsky',\n",
    "              passwd='khqWN6sZlqler3u4CGxoHX4wWF1jeqCC2YfpCiEjiLPTvhrbc4ffuvn0gq1s')\n",
    "        ftp.cwd('site/public/storage/images')\n",
    "        placeFile(ftp,filename=img_name,filedir='input\\\\'+img_name)\n",
    "        print(\"preprocess\")\n",
    "        #preprocess\n",
    "        preprocess = Img_preprocess(filepath = path)\n",
    "        try:\n",
    "            img = preprocess.clear_green(region='se1')\n",
    "            preprocess.save_img(img,name=path)\n",
    "        except Exception:\n",
    "            print('preprocess flail',path)\n",
    "            #\n",
    "        current.append(path)\n",
    "        while len(current)>20:\n",
    "            current.pop(0)\n",
    "        print(\"predict\")\n",
    "        img = predict_and_save(current);\n",
    "\n",
    "        print(\"store prediction\")\n",
    "        #store prediction\n",
    "        ftp.cwd('../')\n",
    "#         ftp.retrlines('LIST')    \n",
    "        ftp.cwd('next-1hr')\n",
    "        placeFile(ftp,filename=img_name,filedir='prediction\\\\'+img_name)\n",
    "        ftp.cwd('../')\n",
    "        ftp.cwd('prediction')\n",
    "        ftp.quit()\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"fail to predict\")\n",
    "except Exception:\n",
    "    print(\"fail to scrappingt\")\n",
    "#s.enter(600, 1, real_time_update, (sc,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1410'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now=datetime.datetime.utcnow()\n",
    "now=now.strftime('%H%M')\n",
    "now=now.replace(now[-1],'0')\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try scraping\n",
      "UTC time right now:2019-01-10 08:38:05.099822, Img timestamp:2019-01-10 08:10:00\n",
      "File path:./input//se1_b08_0810.jpg\n",
      "File Exists\n",
      "UTC time right now:2019-01-10 08:38:05.099822, Img timestamp:2019-01-10 18:10:00\n",
      "File path:./input//se1_b08_1810.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1810.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1810.jpg\n",
      "predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "c:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "c:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\\se1_b08_1810.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1810.jpg\n",
      "226 Transfer complete.\n",
      "try scraping\n",
      "UTC time right now:2019-01-10 08:48:14.748746, Img timestamp:2019-01-10 08:20:00\n",
      "File path:./input//se1_b08_0820.jpg\n",
      "File Exists\n",
      "UTC time right now:2019-01-10 08:48:14.748746, Img timestamp:2019-01-10 18:20:00\n",
      "File path:./input//se1_b08_1820.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1820.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1820.jpg\n",
      "predict\n",
      "prediction\\se1_b08_1820.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1820.jpg\n",
      "226 Transfer complete.\n",
      "try scraping\n",
      "UTC time right now:2019-01-10 08:58:23.552746, Img timestamp:2019-01-10 08:30:00\n",
      "File path:./input//se1_b08_0830.jpg\n",
      "File Exists\n",
      "UTC time right now:2019-01-10 08:58:23.553748, Img timestamp:2019-01-10 18:30:00\n",
      "File path:./input//se1_b08_1830.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1830.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1830.jpg\n",
      "predict\n",
      "prediction\\se1_b08_1830.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1830.jpg\n",
      "226 Transfer complete.\n",
      "try scraping\n",
      "UTC time right now:2019-01-10 09:08:32.808163, Img timestamp:2019-01-10 08:40:00\n",
      "File path:./input//se1_b08_0840.jpg\n",
      "File Exists\n",
      "UTC time right now:2019-01-10 09:08:32.808163, Img timestamp:2019-01-10 18:40:00\n",
      "File path:./input//se1_b08_1840.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1840.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1840.jpg\n",
      "predict\n",
      "prediction\\se1_b08_1840.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1840.jpg\n",
      "226 Transfer complete.\n",
      "try scraping\n",
      "UTC time right now:2019-01-10 09:18:41.894209, Img timestamp:2019-01-10 08:50:00\n",
      "File path:./input//se1_b08_0850.jpg\n",
      "File Exists\n",
      "UTC time right now:2019-01-10 09:18:41.895206, Img timestamp:2019-01-10 18:50:00\n",
      "File path:./input//se1_b08_1850.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1850.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1850.jpg\n",
      "predict\n",
      "prediction\\se1_b08_1850.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1850.jpg\n",
      "226 Transfer complete.\n",
      "try scraping\n",
      "UTC time right now:2019-01-10 09:28:51.280706, Img timestamp:2019-01-10 09:00:00\n",
      "File path:./input//se1_b08_0900.jpg\n",
      "Connection success!\n",
      "UTC time right now:2019-01-10 09:28:52.624286, Img timestamp:2019-01-10 19:00:00\n",
      "File path:./input//se1_b08_1900.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1900.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1900.jpg\n",
      "predict\n",
      "prediction\\se1_b08_1900.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1900.jpg\n",
      "226 Transfer complete.\n",
      "try scraping\n",
      "UTC time right now:2019-01-10 09:39:01.803540, Img timestamp:2019-01-10 09:10:00\n",
      "File path:./input//se1_b08_0910.jpg\n",
      "File Exists\n",
      "UTC time right now:2019-01-10 09:39:01.809524, Img timestamp:2019-01-10 19:10:00\n",
      "File path:./input//se1_b08_1910.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1910.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1910.jpg\n",
      "predict\n",
      "prediction\\se1_b08_1910.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1910.jpg\n",
      "226 Transfer complete.\n",
      "try scraping\n",
      "UTC time right now:2019-01-10 09:49:11.734077, Img timestamp:2019-01-10 09:20:00\n",
      "File path:./input//se1_b08_0920.jpg\n",
      "File Exists\n",
      "UTC time right now:2019-01-10 09:49:11.735060, Img timestamp:2019-01-10 19:20:00\n",
      "File path:./input//se1_b08_1920.jpg\n",
      "File Exists\n",
      "se1 Damaged file\n",
      "\n",
      "se1 Undownload file\n",
      "store image\n",
      "upload file se1_b08_1920.jpg\n",
      "226 Transfer complete.\n",
      "preprocess\n",
      "preprocess flail C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\input\\se1_b08_1920.jpg\n",
      "predict\n",
      "prediction\\se1_b08_1920.jpg\n",
      "store prediction\n",
      "upload file se1_b08_1920.jpg\n",
      "226 Transfer complete.\n"
     ]
    }
   ],
   "source": [
    "s.enter(1, 1, real_time_update, (s,))\n",
    "s.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
