{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as f\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from CovLstm_cell_simply_nocuda import ConvLSTMCell as Covlstm_cell\n",
    "import time\n",
    "from BMSELoss import BMSELoss\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# load data ################\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import color\n",
    "from scipy import ndimage, misc\n",
    "import cloudy\n",
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [color.rgb2gray(imread(path)) for path in image_paths]\n",
    "    #images = [(imread(path)) for path in image_paths]\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray((images), dtype=np.float32)\n",
    "\n",
    "\n",
    "train_dir = cloudy.image_paths_train\n",
    "dir_day = sorted(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #input_size_c = 1 hidden_size = h\n",
    "        #self.conv_act = conv2_act()\n",
    "        self.rnn1_1 = Covlstm_cell(1,1)\n",
    "        self.rnn1_2 = Covlstm_cell(1,1)\n",
    "        self.rnn1_3 = Covlstm_cell(1,1)\n",
    "        self.rnn2_1 = Covlstm_cell(1,1)\n",
    "        #self.rnn2_2 = Covlstm_cell(1,1)\n",
    "       #self.rnn2_3 = Covlstm_cell(1,1)\n",
    "        #self.rnn3_1 = Covlstm_cell(1,1)\n",
    "        #self.rnn3_2 = Covlstm_cell(1,1)\n",
    "        #self.rnn3_3 = Covlstm_cell(1,1)\n",
    "        #self.downsmaple1 =  downsmaple() \n",
    "        #self.downsmaple2 =  downsmaple() \n",
    "    def init_hiden(self):\n",
    "        hidden = []\n",
    "        hidden1_1 = None\n",
    "        hidden1_2 = None\n",
    "        hidden1_3 = None\n",
    "        \n",
    "        hidden2_1 = None\n",
    "        #hidden2_2 = None\n",
    "       #hidden2_3 = None\n",
    "        \n",
    "        #hidden3_1 = None\n",
    "        #hidden3_2 = None\n",
    "        #hidden3_3 = None\n",
    "        hidden.append(hidden1_1)\n",
    "        hidden.append(hidden1_2)\n",
    "        hidden.append(hidden1_3)\n",
    "        hidden.append(hidden2_1)\n",
    "        #hidden.append(hidden2_2)\n",
    "       #hidden.append(hidden2_3)\n",
    "        #hidden.append(hidden3_1)\n",
    "        #hidden.append(hidden3_2)\n",
    "        #hidden.append(hidden3_3)\n",
    "        return hidden\n",
    "        \n",
    "    def forward(self,data,hidden):\n",
    "        hidden1_1 = hidden[0]\n",
    "        hidden1_2 = hidden[1]\n",
    "        hidden1_3 = hidden[2]\n",
    "        \n",
    "        hidden2_1 = hidden[3] \n",
    "        #hidden2_2 = hidden[4]\n",
    "      # hidden2_3 = hidden[5] \n",
    "        \n",
    "        #hidden3_1 = hidden[6]  \n",
    "        #hidden3_2 = hidden[7]  \n",
    "        #hidden3_3 = hidden[8]\n",
    "        #data = self.conv_act(data)\n",
    "        hidden1_1 = self.rnn1_1.forward(data ,hidden1_1)\n",
    "                \n",
    "        hidden1_2_input = hidden1_1[0][0]\n",
    "        hidden1_2_input = hidden1_2_input[:,None,:,:] \n",
    "        hidden1_2 = self.rnn1_2.forward(hidden1_2_input,hidden1_2)\n",
    "        \n",
    "        hidden1_3_input = hidden1_2[0][0]\n",
    "        hidden1_3_input = hidden1_3_input[:,None,:,:] \n",
    "        hidden1_3 = self.rnn1_3.forward(hidden1_3_input,hidden1_3)\n",
    "        \n",
    "        hidden2_1_input = hidden1_3[0][0]\n",
    "        hidden2_1_input = hidden2_1_input[:,None,:,:] \n",
    "        #hidden2_1_input  = self.downsmaple1(hidden2_1_input)\n",
    "        hidden2_1 = self.rnn2_1.forward(hidden2_1_input ,hidden2_1)\n",
    "        '''\n",
    "        hidden2_2_input = hidden2_1[0][0]\n",
    "        hidden2_2_input = hidden2_2_input[:,None,:,:] \n",
    "        hidden2_2 = self.rnn2_2.forward(hidden2_2_input,hidden2_2)\n",
    "        \n",
    "        hidden2_3_input = hidden2_2[0][0]\n",
    "        hidden2_3_input = hidden2_3_input[:,None,:,:] \n",
    "        hidden2_3 = self.rnn2_3.forward(hidden2_3_input,hidden2_3)\n",
    "        \n",
    "        hidden3_1_input = hidden2_2[0][0]\n",
    "        hidden3_1_input = hidden3_1_input[:,None,:,:]  \n",
    "        #hidden3_1_input = self.downsmaple2(hidden3_1_input)\n",
    "        hidden3_1 = self.rnn3_1.forward(hidden3_1_input ,hidden3_1)\n",
    "            \n",
    "        hidden3_2_input = hidden3_1[0][0]\n",
    "        hidden3_2_input = hidden3_2_input[:,None,:,:] \n",
    "        hidden3_2 = self.rnn3_2.forward(hidden3_2_input,hidden3_2)\n",
    "            \n",
    "        hidden3_3_input = hidden3_2[0][0]\n",
    "        hidden3_3_input = hidden3_3_input[:,None,:,:] \n",
    "        hidden3_3 = self.rnn3_3.forward(hidden3_3_input,hidden3_3)'''\n",
    "        #encoder_out = hidden3_3[0][0][0]\n",
    "        #encoder_out = hidden3_3[0]\n",
    "        encoder_out = hidden2_1[0]\n",
    "        hidden = []\n",
    "        hidden.append(hidden1_1)\n",
    "        hidden.append(hidden1_2)\n",
    "        hidden.append(hidden1_3)\n",
    "        hidden.append(hidden2_1)\n",
    "        #hidden.append(hidden2_2)\n",
    "       #hidden.append(hidden2_3)\n",
    "        #hidden.append(hidden3_1)\n",
    "        #hidden.append(hidden3_2)\n",
    "        #hidden.append(hidden3_3)\n",
    "        '''for i in range(0,9):\n",
    "            hidden_encoder.append(hidden1_1,hidden1_2,hidden1_3,\n",
    "                                 hidden2_1,hidden2_2,hidden2_3,\n",
    "                                 hidden3_1,hidden3_2,hidden3_3)'''\n",
    "        # Dont care about hidden states\n",
    "        return encoder_out,hidden\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #input_size_c = 1 hidden_size = h\n",
    "        num_c = [1, 1, 1]\n",
    "        h = [1,1,1]\n",
    "        #self.conv_act = conv2_act()\n",
    "        self.rnn1_1 = Covlstm_cell(1,1)\n",
    "        self.rnn1_2 = Covlstm_cell(1,1)\n",
    "        self.rnn1_3 = Covlstm_cell(1,1)\n",
    "        self.rnn2_1 = Covlstm_cell(1,1)\n",
    "        #self.rnn2_2 = Covlstm_cell(1,1)\n",
    "        #elf.rnn2_3 = Covlstm_cell(1,1)\n",
    "        #self.rnn3_1 = Covlstm_cell(1,1)\n",
    "        #self.rnn3_2 = Covlstm_cell(1,1)\n",
    "        #self.rnn3_3 = Covlstm_cell(1,1)\n",
    "        #self.upsmaple1 =  upsmaple() \n",
    "        #self.upsmaple2 =  upsmaple() \n",
    "        #self.deconv1 = deconv2_act()\n",
    "        # self.deconv2 = deconv2_act(inplanes=8, out_channels=8, kernel_size=4, stride=2, padding=1)\n",
    "        #self.conv_final = conv2_act()\n",
    "        #self.conv_final = conv2_act()\n",
    "\n",
    "        #self.conv_pre = conv2_act()\n",
    "    '''def set_h0(self,encoder):\n",
    "        self.rnn1_1_h = encoder.rnn3_3_h\n",
    "        self.rnn1_2_h = encoder.rnn3_2_h\n",
    "        self.rnn1_3_h = encoder.rnn3_1_h\n",
    "        self.rnn2_1_h = encoder.rnn2_3_h\n",
    "        self.rnn2_2_h = encoder.rnn2_2_h\n",
    "        self.rnn2_3_h = encoder.rnn2_1_h\n",
    "        self.rnn3_1_h = encoder.rnn1_2_h\n",
    "        self.rnn3_2_h = encoder.rnn1_1_h'''\n",
    "    \n",
    "    '''def init_h0(self,hidden_en):\n",
    "        self.hidden1_1 = hidden_en[8]\n",
    "        self.hidden1_2 = hidden_en[7]\n",
    "        self.hidden1_3 = hidden_en[6]\n",
    "        \n",
    "        self.hidden2_1 = hidden_en[5]\n",
    "        self.hidden2_2 = hidden_en[4]\n",
    "        self.hidden2_3 = hidden_en[3]\n",
    "        \n",
    "        self.hidden3_1 = hidden_en[2]\n",
    "        self.hidden3_2 = hidden_en[1]\n",
    "        self.hidden3_3 = hidden_en[0]'''\n",
    "        \n",
    "    def forward(self,data,hidden_en):\n",
    "        #print('-----data size------')\n",
    "        #print(data.size())\n",
    "        #data = self.conv_act(data)\n",
    "        hidden1_1 = hidden_en[3]\n",
    "        hidden1_2 = hidden_en[2]\n",
    "        hidden1_3 = hidden_en[1]\n",
    "        \n",
    "        hidden2_1 = hidden_en[0]\n",
    "        #hidden2_2 = hidden_en[1]\n",
    "        #idden2_3 = hidden_en[0]\n",
    "        \n",
    "        #hidden3_1 = hidden_en[2]\n",
    "        #hidden3_2 = hidden_en[1]\n",
    "        #hidden3_3 = hidden_en[0]\n",
    "        \n",
    "        \n",
    "        hidden1_1 = self.rnn1_1.forward(data,hidden1_1)\n",
    "                \n",
    "        hidden1_2_input = hidden1_1[0][0]\n",
    "        hidden1_2_input = hidden1_2_input[:,None,:,:] \n",
    "        hidden1_2 = self.rnn1_2.forward(hidden1_2_input,hidden1_2)\n",
    "        \n",
    "        hidden1_3_input = hidden1_2[0][0]\n",
    "        hidden1_3_input = hidden1_3_input[:,None,:,:] \n",
    "        #hidden1_3_input = self.upsmaple1(hidden1_3_input)\n",
    "        hidden1_3 = self.rnn1_3.forward(hidden1_3_input,hidden1_3)\n",
    "       \n",
    "        hidden2_1_input = hidden1_3[0][0]\n",
    "        hidden2_1_input = hidden2_1_input[:,None,:,:] \n",
    "        hidden2_1 = self.rnn2_1.forward(hidden2_1_input ,hidden2_1)\n",
    "        ''' \n",
    "        hidden2_2_input = hidden2_1[0][0]\n",
    "        hidden2_2_input = hidden2_2_input[:,None,:,:] \n",
    "        hidden2_2 = self.rnn2_2.forward(hidden2_2_input,hidden2_2)\n",
    "        \n",
    "        hidden2_3_input = hidden2_2[0][0]\n",
    "        hidden2_3_input = hidden2_3_input[:,None,:,:] \n",
    "        hidden2_3 = self.rnn2_3.forward(hidden2_3_input,hidden2_3)\n",
    "       \n",
    "        hidden3_1_input = hidden2_3[0][0]\n",
    "        hidden3_1_input = hidden3_1_input[:,None,:,:]  \n",
    "        #hidden3_1_input = self.upsmaple2(hidden3_1_input)\n",
    "        hidden3_1 = self.rnn3_1.forward(hidden3_1_input ,hidden3_1)\n",
    "            \n",
    "        hidden3_2_input = hidden3_1[0][0]\n",
    "        hidden3_2_input = hidden3_2_input[:,None,:,:] \n",
    "        hidden3_2 = self.rnn3_2.forward(hidden3_2_input,hidden3_2)\n",
    "            \n",
    "        hidden3_3_input = hidden3_2[0][0]\n",
    "        hidden3_3_input = hidden3_3_input[:,None,:,:] \n",
    "        hidden3_3 = self.rnn3_3.forward(hidden3_3_input,hidden3_3)'''\n",
    "        out = hidden2_1[0]\n",
    "        #print('-----out data size------')\n",
    "        #print(out.size())\n",
    "        \n",
    "        #out = self.deconv1(out)\n",
    "        #print('-----out data size------')\n",
    "        #print(out.size())\n",
    "        #out = self.conv_final(out)\n",
    "        #out = self.conv_pre(out)\n",
    "        # Dont care about hidden states\n",
    "        hidden = []\n",
    "        hidden.append(hidden1_1)\n",
    "        hidden.append(hidden1_2)\n",
    "        hidden.append(hidden1_3)\n",
    "        hidden.append(hidden2_1)\n",
    "        #hidden.append(hidden2_2)\n",
    "       #hidden.append(hidden2_3)\n",
    "        return out,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #input_size_c = 1 hidden_size = h\n",
    "        self.enc  = Encoder()\n",
    "        self.dec  = Decoder()\n",
    "        \n",
    "    def forward(self,data,epoch):\n",
    "        hidden_en = self.enc.init_hiden()\n",
    "        T_en = 9 # same seq\n",
    "        T_en = T_en+epoch\n",
    "        for t in range(epoch, T_en):\n",
    "            enc_output,hidden_en = self.enc(data[t],hidden_en)\n",
    "        #self.dec.init_h0(hidden_en)\n",
    "        dec_output = enc_output\n",
    "\n",
    "        for t in range(epoch, T_en):\n",
    "            dec_output,hidden_en= self.dec(dec_output,hidden_en)\n",
    "        dec_output = dec_output[0][0]\n",
    "        return dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\CovLstm_cell_simply_nocuda.py:14: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  torch.nn.init.xavier_normal(self.Gates.weight)\n",
      "C:\\Users\\tanintem\\Desktop\\deepsky real time updater\\CovLstm_cell_simply_nocuda.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  torch.nn.init.constant(self.Gates.bias, 0)\n"
     ]
    }
   ],
   "source": [
    "model = TraModel()\n",
    "dic_param = torch.load('model/model8_10seq_10000dataset.pt',lambda s,_:s)\n",
    "model.load_state_dict(dic_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('enc.rnn1_1.Gates.weight', tensor([[[[-0.0782,  0.0794, -0.0716],\n",
       "                        [ 0.1205,  0.1209,  0.2695],\n",
       "                        [-0.0330,  0.1305, -0.0156]],\n",
       "              \n",
       "                       [[-0.0408,  0.0338,  0.0359],\n",
       "                        [-0.1166,  0.3647, -0.4417],\n",
       "                        [-0.0632,  0.3111,  0.0887]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1132,  0.0345,  0.4336],\n",
       "                        [-0.1459,  0.1837,  0.2158],\n",
       "                        [ 0.0370, -0.1417,  0.1265]],\n",
       "              \n",
       "                       [[ 0.0057, -0.0412, -0.0752],\n",
       "                        [-0.0065,  0.0066, -0.2366],\n",
       "                        [-0.3041, -0.2084, -0.3177]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1129, -0.3125,  0.1403],\n",
       "                        [ 0.1471,  0.3082,  0.1176],\n",
       "                        [ 0.0758, -0.0846,  0.0269]],\n",
       "              \n",
       "                       [[-0.2251,  0.2249, -0.2233],\n",
       "                        [-0.1104, -0.2654, -0.0211],\n",
       "                        [-0.2524, -0.2907, -0.2021]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1831,  0.0754,  0.0231],\n",
       "                        [ 0.0474, -0.0710, -0.0540],\n",
       "                        [-0.1702, -0.2864,  0.2984]],\n",
       "              \n",
       "                       [[ 0.0266, -0.1322,  0.0689],\n",
       "                        [ 0.0128,  0.0662,  0.1073],\n",
       "                        [ 0.1566,  0.0780, -0.0069]]]])),\n",
       "             ('enc.rnn1_1.Gates.bias',\n",
       "              tensor([ 0.0030, -0.0068,  0.0283,  0.0250])),\n",
       "             ('enc.rnn1_2.Gates.weight', tensor([[[[-0.4108, -0.4704, -0.1154],\n",
       "                        [-0.3307,  0.1481, -0.1481],\n",
       "                        [ 0.0012, -0.1483, -0.1258]],\n",
       "              \n",
       "                       [[ 0.0785,  0.0421, -0.2254],\n",
       "                        [-0.2788, -0.0944,  0.2424],\n",
       "                        [-0.0146, -0.1080, -0.2562]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2469, -0.2267, -0.0421],\n",
       "                        [-0.3699, -0.1806, -0.1882],\n",
       "                        [-0.1504,  0.1290, -0.0223]],\n",
       "              \n",
       "                       [[-0.2478, -0.2361, -0.4225],\n",
       "                        [ 0.1822,  0.2426, -0.2015],\n",
       "                        [ 0.0141, -0.0210, -0.0826]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.5287, -0.0351, -0.2381],\n",
       "                        [-0.2948, -0.1384,  0.0943],\n",
       "                        [-0.0383, -0.1585, -0.3400]],\n",
       "              \n",
       "                       [[-0.2057,  0.0262, -0.3764],\n",
       "                        [-0.0264,  0.0084, -0.1804],\n",
       "                        [-0.2523, -0.1368, -0.3108]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1359,  0.0393, -0.1441],\n",
       "                        [-0.0404,  0.3547, -0.2281],\n",
       "                        [ 0.1708,  0.3166,  0.1822]],\n",
       "              \n",
       "                       [[-0.1126,  0.0447,  0.0602],\n",
       "                        [ 0.2684,  0.0097, -0.0129],\n",
       "                        [-0.0139, -0.2207, -0.0230]]]])),\n",
       "             ('enc.rnn1_2.Gates.bias',\n",
       "              tensor([ 0.0132,  0.0446,  0.0051, -0.0098])),\n",
       "             ('enc.rnn1_3.Gates.weight', tensor([[[[ 0.1506, -0.2261,  0.1882],\n",
       "                        [-0.2966, -0.2228, -0.3935],\n",
       "                        [-0.2031,  0.1088, -0.2298]],\n",
       "              \n",
       "                       [[ 0.1000,  0.5485,  0.4723],\n",
       "                        [ 0.2208,  0.2965,  0.0703],\n",
       "                        [ 0.0228,  0.0270,  0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0246, -0.3038,  0.0996],\n",
       "                        [-0.2098, -0.0663, -0.2134],\n",
       "                        [ 0.0986, -0.2551,  0.0392]],\n",
       "              \n",
       "                       [[-0.1107,  0.0437,  0.1818],\n",
       "                        [ 0.3338,  0.2636,  0.4364],\n",
       "                        [ 0.2229,  0.0504,  0.1172]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1909, -0.1337, -0.0020],\n",
       "                        [-0.0951, -0.1063, -0.2037],\n",
       "                        [ 0.1863, -0.1758, -0.1384]],\n",
       "              \n",
       "                       [[ 0.1730,  0.0743, -0.1864],\n",
       "                        [ 0.8009,  0.0469,  0.0685],\n",
       "                        [ 0.4591,  0.0066,  0.1736]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1956, -0.0388, -0.2083],\n",
       "                        [ 0.1463, -0.0536, -0.0572],\n",
       "                        [-0.1613, -0.1506, -0.1393]],\n",
       "              \n",
       "                       [[-0.1854,  0.1483, -0.0770],\n",
       "                        [-0.0395, -0.2132,  0.0933],\n",
       "                        [ 0.1748,  0.1182, -0.0602]]]])),\n",
       "             ('enc.rnn1_3.Gates.bias',\n",
       "              tensor([0.0160, 0.0582, 0.0426, 0.0102])),\n",
       "             ('enc.rnn2_1.Gates.weight', tensor([[[[-0.1199,  0.4049, -0.0257],\n",
       "                        [ 0.3954, -0.0437,  0.1719],\n",
       "                        [ 0.2353, -0.2609,  0.3964]],\n",
       "              \n",
       "                       [[ 0.0981, -0.3884,  0.0009],\n",
       "                        [ 0.1569,  0.0836,  0.0834],\n",
       "                        [-0.3029,  0.2086,  0.1444]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0770,  0.0774,  0.5149],\n",
       "                        [ 0.4912,  0.3110,  0.1796],\n",
       "                        [ 0.1329,  0.0505, -0.1717]],\n",
       "              \n",
       "                       [[-0.2542,  0.2082, -0.0553],\n",
       "                        [-0.0043,  0.0138,  0.0303],\n",
       "                        [-0.1474, -0.0896,  0.4142]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2100,  0.0571, -0.0539],\n",
       "                        [ 0.1892,  0.1383,  0.1100],\n",
       "                        [ 0.0563,  0.3652, -0.0413]],\n",
       "              \n",
       "                       [[ 0.1647, -0.2743, -0.0434],\n",
       "                        [-0.1933,  0.1471,  0.4171],\n",
       "                        [-0.2234,  0.1431, -0.5115]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2227,  0.1040,  0.2288],\n",
       "                        [-0.1078,  0.1199,  0.0105],\n",
       "                        [ 0.1262,  0.3252,  0.1447]],\n",
       "              \n",
       "                       [[ 0.0149,  0.1611,  0.2517],\n",
       "                        [-0.2159,  0.2976,  0.0071],\n",
       "                        [ 0.4291,  0.0553,  0.4064]]]])),\n",
       "             ('enc.rnn2_1.Gates.bias',\n",
       "              tensor([0.0251, 0.0310, 0.0099, 0.0677])),\n",
       "             ('dec.rnn1_1.Gates.weight', tensor([[[[ 0.2344, -0.1329,  0.1959],\n",
       "                        [-0.2207,  0.0581,  0.1746],\n",
       "                        [ 0.1431,  0.0340,  0.1446]],\n",
       "              \n",
       "                       [[ 0.0367,  0.0378,  0.4491],\n",
       "                        [-0.1491,  0.0328, -0.1606],\n",
       "                        [ 0.1141, -0.0180,  0.1562]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0820,  0.2488, -0.2312],\n",
       "                        [ 0.2302,  0.3413,  0.3624],\n",
       "                        [ 0.2722, -0.0415,  0.1639]],\n",
       "              \n",
       "                       [[ 0.2903, -0.0643, -0.2959],\n",
       "                        [ 0.1705,  0.0318,  0.1528],\n",
       "                        [ 0.0750,  0.1521,  0.2674]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2219,  0.1849,  0.4168],\n",
       "                        [ 0.1891, -0.1592,  0.0179],\n",
       "                        [-0.0739,  0.5189,  0.1098]],\n",
       "              \n",
       "                       [[ 0.2984,  0.1317,  0.1412],\n",
       "                        [ 0.0572, -0.1687, -0.1167],\n",
       "                        [-0.0200,  0.2466,  0.0040]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0099,  0.1084, -0.0596],\n",
       "                        [ 0.3431, -0.4861,  0.0520],\n",
       "                        [-0.0530,  0.2558, -0.1105]],\n",
       "              \n",
       "                       [[ 0.0586, -0.0538,  0.4745],\n",
       "                        [-0.2545, -0.0424,  0.3224],\n",
       "                        [-0.0940,  0.0746, -0.1320]]]])),\n",
       "             ('dec.rnn1_1.Gates.bias',\n",
       "              tensor([0.0839, 0.1096, 0.1166, 0.0908])),\n",
       "             ('dec.rnn1_2.Gates.weight', tensor([[[[ 0.0499, -0.1763,  0.2423],\n",
       "                        [-0.1078, -0.3908,  0.0908],\n",
       "                        [ 0.0003, -0.1706, -0.0563]],\n",
       "              \n",
       "                       [[ 0.1732,  0.2856,  0.3652],\n",
       "                        [ 0.2190,  0.6713, -0.3878],\n",
       "                        [-0.2805,  0.0485,  0.3341]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.5224,  0.1882,  0.1140],\n",
       "                        [ 0.1714, -0.0356,  0.2685],\n",
       "                        [-0.2018,  0.0590,  0.1651]],\n",
       "              \n",
       "                       [[-0.1288,  0.0909,  0.1861],\n",
       "                        [-0.1583,  0.2942,  0.3338],\n",
       "                        [ 0.3500,  0.5114,  0.1355]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0006,  0.2050, -0.1134],\n",
       "                        [-0.2740, -0.3162,  0.1611],\n",
       "                        [-0.4628,  0.0189, -0.0093]],\n",
       "              \n",
       "                       [[ 0.4257,  0.5441, -0.0759],\n",
       "                        [ 0.2287,  0.2586,  0.1117],\n",
       "                        [ 0.0777, -0.1893,  0.1062]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0341, -0.1223,  0.0472],\n",
       "                        [ 0.3666,  0.3061,  0.0587],\n",
       "                        [-0.4433,  0.3578, -0.1060]],\n",
       "              \n",
       "                       [[ 0.1170, -0.1682, -0.0369],\n",
       "                        [ 0.0634, -0.1904,  0.6347],\n",
       "                        [ 0.0465, -0.0526,  0.2760]]]])),\n",
       "             ('dec.rnn1_2.Gates.bias',\n",
       "              tensor([0.0255, 0.0776, 0.0144, 0.0529])),\n",
       "             ('dec.rnn1_3.Gates.weight', tensor([[[[ 0.0824,  0.4300, -0.0967],\n",
       "                        [-0.3896,  0.1214,  0.1680],\n",
       "                        [ 0.3139,  0.1539, -0.0275]],\n",
       "              \n",
       "                       [[-0.2394, -0.1255,  0.2337],\n",
       "                        [-0.0817,  0.1830,  0.0466],\n",
       "                        [ 0.0567,  0.0383,  0.1524]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0140, -0.1281, -0.1846],\n",
       "                        [ 0.1380, -0.0181,  0.1980],\n",
       "                        [ 0.0481, -0.0581, -0.3208]],\n",
       "              \n",
       "                       [[ 0.2166,  0.2182,  0.2579],\n",
       "                        [ 0.4054, -0.0357, -0.0041],\n",
       "                        [-0.1635,  0.2580,  0.2601]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2645,  0.1391,  0.3171],\n",
       "                        [ 0.3278,  0.1879,  0.3455],\n",
       "                        [ 0.0265, -0.0091,  0.3213]],\n",
       "              \n",
       "                       [[ 0.1180,  0.3194,  0.2718],\n",
       "                        [-0.0935,  0.3157,  0.3085],\n",
       "                        [ 0.1333,  0.0072,  0.4237]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1155,  0.0645, -0.1576],\n",
       "                        [-0.0014,  0.1216,  0.0940],\n",
       "                        [ 0.0544,  0.2983, -0.2218]],\n",
       "              \n",
       "                       [[ 0.0797,  0.1403, -0.3893],\n",
       "                        [ 0.2399,  0.2196, -0.1408],\n",
       "                        [ 0.0604, -0.2266,  0.0501]]]])),\n",
       "             ('dec.rnn1_3.Gates.bias',\n",
       "              tensor([0.0646, 0.0916, 0.1180, 0.0509])),\n",
       "             ('dec.rnn2_1.Gates.weight', tensor([[[[ 0.0307, -0.0876,  0.1236],\n",
       "                        [ 0.3325, -0.0082,  0.0127],\n",
       "                        [ 0.2096,  0.6005,  0.2640]],\n",
       "              \n",
       "                       [[ 0.3132, -0.0295,  0.2876],\n",
       "                        [-0.2626, -0.0114, -0.3112],\n",
       "                        [ 0.2589,  0.1077, -0.2113]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1872,  0.1830,  0.1195],\n",
       "                        [ 0.1594,  0.1192,  0.0679],\n",
       "                        [ 0.0368,  0.2715, -0.1862]],\n",
       "              \n",
       "                       [[ 0.0841, -0.0305,  0.1237],\n",
       "                        [-0.0227, -0.0478, -0.1100],\n",
       "                        [ 0.0566, -0.1650,  0.4952]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2543,  0.4362, -0.1886],\n",
       "                        [ 0.2970, -0.1342,  0.1910],\n",
       "                        [-0.0607,  0.1930,  0.1753]],\n",
       "              \n",
       "                       [[ 0.0660,  0.3452,  0.1276],\n",
       "                        [ 0.2041,  0.0445,  0.0031],\n",
       "                        [ 0.0371,  0.1877,  0.0677]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0062,  0.5266,  0.3485],\n",
       "                        [ 0.1399,  0.1184,  0.2147],\n",
       "                        [ 0.2702, -0.1432,  0.3934]],\n",
       "              \n",
       "                       [[-0.1616, -0.0631,  0.0206],\n",
       "                        [ 0.5717,  0.2346,  0.2225],\n",
       "                        [ 0.0619,  0.0820,  0.3252]]]])),\n",
       "             ('dec.rnn2_1.Gates.bias',\n",
       "              tensor([0.1251, 0.1099, 0.1630, 0.1726]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_param\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for predict 3hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model,train_dir):\n",
    "    seq = 9\n",
    "    train_data = load_images(train_dir)\n",
    "    Nx_input = torch.from_numpy(train_data)\n",
    "    torch.manual_seed(0)\n",
    "    x_input = Nx_input[:]/255\n",
    "    x_input = x_input[:,None,None,:,:]\n",
    "    x_input = Variable(x_input)\n",
    "\n",
    "    epoch=0\n",
    "    T_en = 9\n",
    "    #T_en = T_en+epoch\n",
    "    output = model(x_input,epoch)\n",
    "    img = output.cpu() \n",
    "    img = img.data.numpy()\n",
    "    #img.shape\n",
    "    img = img*255\n",
    "    image_name = \"prediction_3hr/\"+train_dir[-1][-16:] \n",
    "    print(image_name)\n",
    "    scipy.misc.imsave(image_name, img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# load data ################\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import color\n",
    "from scipy import ndimage, misc\n",
    "import cloudy\n",
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [color.rgb2gray(imread(path)) for path in image_paths]\n",
    "    \n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray((images), dtype=np.float32)\n",
    "current = cloudy.get_data_dir('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_3hr/se1_b08_2350.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tanintem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "    img = prediction(model,current[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20a63946e10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
